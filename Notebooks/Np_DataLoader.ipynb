{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ShallowLearn.ImageHelper as ih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ShallowLearn.IndiceFeatures import get_feature_order\n",
    "from ShallowLearn.band_mapping import band_mapping\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ShallowLearn.Training import create_row_data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [i[0] for i in get_feature_order()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.append(\"mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(band_mapping.keys()) + features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_dataset, original_shape = create_row_data_frame(\"/media/ziad/Expansion/Cleaned_Data_Directory/\", \"imgs.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.load(\"/media/ziad/Expansion/Cleaned_Data_Directory/indices.npy\")\n",
    "masks = np.load(\"/media/ziad/Expansion/Cleaned_Data_Directory/masks.npy\")\n",
    "images = np.load(\"/media/ziad/Expansion/Cleaned_Data_Directory/imgs.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = np.uint8(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_combined = np.concatenate((images, indices, masks),axis = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer, MinMaxScaler\n",
    "\n",
    "# Define the columns for each transformer\n",
    "power_transformer_columns = ['B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B09', 'B10', 'B11', 'B12','calculate_water_surface_index']\n",
    "standard_scaler_columns = ['bgr', 'ci', 'ndci', 'oci', 'ssi', 'ti', 'wqi']\n",
    "minmax_scaler_columns = ['B01', 'calculate_pseudo_subsurface_depth']\n",
    "passthrough_columns = ['mask']\n",
    "# Create transformers\n",
    "power_transformer_transformer = ('power_transformer', PowerTransformer(), power_transformer_columns)\n",
    "standard_scaler_transformer = ('standard_scaler', StandardScaler(), standard_scaler_columns)\n",
    "minmax_scaler_transformer = ('minmax_scaler', MinMaxScaler(), minmax_scaler_columns)\n",
    "passthrough_transformer = ('passthrough', 'passthrough', passthrough_columns)\n",
    "# Initialize ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        power_transformer_transformer,\n",
    "        standard_scaler_transformer,\n",
    "        minmax_scaler_transformer,\n",
    "        passthrough_transformer\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Initialize Pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipeline.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_expanded = data_combined.reshape(-1, len(features))\n",
    "df = pd.DataFrame(data_expanded, columns = features).dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_back = data_expanded.reshape(54 ,  data_combined.shape[1], data_combined.shape[2], len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ih.plot_rgb(reshaped_back[0], plot= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = pd.DataFrame(pipeline.fit_transform(df), columns = pipeline.feature_names_in_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.pipeline import Pipeline\n",
    "import umap\n",
    "\n",
    "# Here we assume you have a data X\n",
    "# X = your_data\n",
    "\n",
    "# Pipeline for PCA followed by t-SNE\n",
    "pipeline_pca_tsne = Pipeline([\n",
    "    ('pca', PCA(n_components=5)),  # reduce dimensionality before t-SNE\n",
    "    ('tsne', TSNE(n_components=2))  # you usually want 2D or 3D for visualization\n",
    "])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = pipeline_pca_tsne.fit_transform(row_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(transformed_data[:,0], transformed_data[:,1], 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_model = PCA(n_components=30)\n",
    "transformed_data = pca_model.fit_transform(row_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract explained variance ratio from pca_modified\n",
    "explained_variance_ratio = pca_model.explained_variance_ratio_\n",
    "\n",
    "# Create a cumulative sum of explained variance ratio\n",
    "cumulative_explained_variance = explained_variance_ratio.cumsum()\n",
    "\n",
    "# Plot the individual and cumulative explained variance ratios\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Individual explained variance ratio\n",
    "plt.bar(range(len(explained_variance_ratio)), explained_variance_ratio, alpha=0.5, label='Individual Explained Variance')\n",
    "\n",
    "# Cumulative explained variance ratio\n",
    "plt.step(range(len(cumulative_explained_variance)), cumulative_explained_variance, where='mid', label='Cumulative Explained Variance', color='red')\n",
    "\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.xlabel('Principal Components')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_images = row_dataset.to_numpy().reshape(original_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(transformed_data[:,0], transformed_data[:,1], 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "#set figure size\n",
    "#import kmeans\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans_pca = KMeans(n_clusters=4)  # or however many clusters you want\n",
    "\n",
    "kmeans_pca.fit(transformed_data)\n",
    "labels_umap_pca = kmeans_pca.labels_\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,25))\n",
    "\n",
    "plt.scatter(transformed_data[:,0], transformed_data[:,1], c=labels_umap_pca, cmap='rainbow')\n",
    "plt.title('PCs on whole Images after correction')\n",
    "plt.ticklabel_format(style='plain', axis='x',useOffset=False)\n",
    "\n",
    "# Plot image on top of the scatter plot in the location of the point \n",
    "for index, i in enumerate(labels_umap_pca):\n",
    "    img = ih.plot_rgb(original_images[index])\n",
    "    im = OffsetImage(img, zoom=0.2)  # Adjust zoom here\n",
    "    ab = AnnotationBbox(im, (transformed_data[index,0], transformed_data[index,1]), box_alignment=(0.5, 0.5), \n",
    "                        bboxprops = dict(edgecolor='none', alpha=0.5, boxstyle=\"square,pad=0\"))\n",
    "    plt.gca().add_artist(ab)\n",
    "\n",
    "# Print labels for each point\n",
    "label_dict = {}\n",
    "for i, txt in enumerate(labels_umap_pca):\n",
    "    # Only print one label for each cluster\n",
    "    if txt not in label_dict:\n",
    "        label_dict[txt] = 1\n",
    "        plt.annotate(txt, (transformed_data[i,0], transformed_data[i,1]), color = 'red')\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import ImageHelper as ih\n",
    "\n",
    "def plot_pca_with_images(transformed_data, original_images, n_clusters=4, figsize=(15,25), zoom_level=0.2):\n",
    "    # Perform KMeans clustering\n",
    "    kmeans_pca = KMeans(n_clusters=n_clusters)\n",
    "    kmeans_pca.fit(transformed_data)\n",
    "    labels_umap_pca = kmeans_pca.labels_\n",
    "    \n",
    "    # Set figure size and plot scatter points\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.scatter(transformed_data[:,0], transformed_data[:,1], c=labels_umap_pca, cmap='rainbow')\n",
    "    plt.title('PCs on whole Images after correction')\n",
    "    plt.ticklabel_format(style='plain', axis='x', useOffset=False)\n",
    "    \n",
    "    # Overlay images on scatter plot\n",
    "    for index, i in enumerate(labels_umap_pca):\n",
    "        img = ih.plot_rgb(original_images[index])\n",
    "        im = OffsetImage(img, zoom=zoom_level)\n",
    "        ab = AnnotationBbox(im, (transformed_data[index,0], transformed_data[index,1]), box_alignment=(0.5, 0.5), \n",
    "                            bboxprops=dict(edgecolor='none', alpha=0.5, boxstyle=\"square,pad=0\"))\n",
    "        plt.gca().add_artist(ab)\n",
    "    \n",
    "    # Print labels for each point\n",
    "    label_dict = {}\n",
    "    for i, txt in enumerate(labels_umap_pca):\n",
    "        if txt not in label_dict:\n",
    "            label_dict[txt] = 1\n",
    "            plt.annotate(txt, (transformed_data[i,0], transformed_data[i,1]), color='red')\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pca_with_images(transformed_data, original_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,25))\n",
    "\n",
    "plt.scatter(transformed_data[:,0], transformed_data[:,1], c=labels_umap_pca, cmap='rainbow')\n",
    "plt.title('PCs on whole Images after correction')\n",
    "plt.ticklabel_format(style='plain', axis='x',useOffset=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ShallowLearn.RadiometricNormalisation import histogram_matching, pca_based_normalization, pca_filter_and_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = original_images[1]\n",
    "plt.title(kmeans_pca.predict(transformed_data[0].reshape(2, -1).T))\n",
    "ih.plot_rgb(ref, plot = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data[0].reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_dataset = []\n",
    "\n",
    "pcs_after_tf = []\n",
    "for index, label in enumerate(labels_umap_pca):\n",
    "    if label == 0 or label == 2:\n",
    "        normalised_img = pca_based_normalization(original_images[index], ref)\n",
    "        transformed_img = pca_model.transform(normalised_img.reshape(1, -1))\n",
    "        pcs_after_tf.append(transformed_img)\n",
    "        fig, ax = plt.subplots(1, 2, figsize = (10, 10))\n",
    "        plt.title(kmeans_pca.predict(transformed_data[index].reshape(2, -1).T))\n",
    "        ax[0].set_title(\"Original image\")\n",
    "        ax[1].set_title(\"Normalised image\")\n",
    "        ax[0].imshow(ih.plot_rgb(original_images[index]))\n",
    "        ax[1].imshow(ih.plot_rgb(normalised_img))\n",
    "        modified_dataset.append(normalised_img)\n",
    "    else:\n",
    "        modified_dataset.append(original_images[index])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_array = np.array(modified_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"/media/ziad/Expansion/Cleaned_Data_Directory/radiometrically_normalized.npy\", modified_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcs_after_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcs_after_tf = np.array(pcs_after_tf).reshape(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcs_after_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Pipeline for PCA followed by t-SNE\n",
    "# pipeline_pca_tsne = Pipeline([\n",
    "#     ('pca', PCA(n_components=5)),  # reduce dimensionality before t-SNE\n",
    "#     ('tsne', TSNE(n_components=2))  # you usually want 2D or 3D for visualization\n",
    "# ])\n",
    "\n",
    "\n",
    "pca_modified= PCA(n_components=30)\n",
    "\n",
    "pca_modified_array = pca_modified.fit_transform(modified_array.reshape(54, -1))\n",
    "print(pca_modified.explained_variance_ratio_)\n",
    "plt.figure(figsize=(15,25))\n",
    "\n",
    "plt.scatter(pca_modified_array[:,0], pca_modified_array[:,1], c=labels_umap_pca, cmap='rainbow')\n",
    "#set log scale\n",
    "plt.gca().set_yscale('symlog')\n",
    "plt.gca().set_xscale('symlog')\n",
    "\n",
    "plt.title('PCs on whole Images after correction')\n",
    "# plt.ticklabel_format(style='plain', axis='x',useOffset=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract explained variance ratio from pca_modified\n",
    "explained_variance_ratio = pca_modified.explained_variance_ratio_\n",
    "\n",
    "# Create a cumulative sum of explained variance ratio\n",
    "cumulative_explained_variance = explained_variance_ratio.cumsum()\n",
    "\n",
    "# Plot the individual and cumulative explained variance ratios\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Individual explained variance ratio\n",
    "plt.bar(range(len(explained_variance_ratio)), explained_variance_ratio, alpha=0.5, label='Individual Explained Variance')\n",
    "\n",
    "# Cumulative explained variance ratio\n",
    "plt.step(range(len(cumulative_explained_variance)), cumulative_explained_variance, where='mid', label='Cumulative Explained Variance', color='red')\n",
    "\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.xlabel('Principal Components')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,25))\n",
    "\n",
    "plt.scatter(transformed_data[:,0], transformed_data[:,1], c=labels_umap_pca, cmap='rainbow')\n",
    "plt.scatter(pcs_after_tf[:,0], pcs_after_tf[:,1], c='black', cmap='rainbow')\n",
    "#set log scale\n",
    "plt.gca().set_yscale('symlog')\n",
    "plt.gca().set_xscale('symlog')\n",
    "\n",
    "plt.title('PCs on whole Images after correction')\n",
    "# plt.ticklabel_format(style='plain', axis='x',useOffset=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline for PCA followed by UMAP\n",
    "pipeline_pca_umap = Pipeline([\n",
    "    ('pca', PCA(n_components=5)),  # reduce dimensionality before UMAP\n",
    "    ('umap', umap.UMAP(n_components=2))  # you usually want 2D or 3D for visualization\n",
    "])\n",
    "\n",
    "# Pipeline for just PCA\n",
    "pipeline_pca = Pipeline([\n",
    "    ('pca', PCA(n_components=2))  # or however many components you want\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_rows = images.reshape(54, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "image_rows = scaler.fit_transform(image_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=10)\n",
    "pca_X = pca.fit_transform(image_rows)\n",
    "\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "\n",
    "print(explained_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans_pca_X = KMeans(n_clusters=3)  # or however many clusters you want\n",
    "\n",
    "kmeans_pca_X.fit(pca_X)\n",
    "labels_pca = kmeans_pca_X.labels_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.title(\"Scaled PCs with whole images as input\")\n",
    "plt.scatter(pca_X[:,0], pca_X[:,1],c=labels_pca,cmap='viridis')\n",
    "plt.gca().set_xlabel(\"PC0\")\n",
    "plt.gca().set_ylabel(\"PC1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_model =  umap.UMAP(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = umap_model.fit_transform(pca_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(embedding[:,0], embedding[:,1], 'o', markersize=2, color='blue', alpha=0.5, label='embedding')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kmeans_image_rows = KMeans(n_clusters=2)  # or however many clusters you want\n",
    "\n",
    "kmeans_image_rows.fit(embedding)\n",
    "labels_pca_umap = kmeans_image_rows.labels_\n",
    "\n",
    "# Create a 2D scatter plot for PCA -> t-SNE with points colored by their cluster membership\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], c=labels_pca_umap, s=10, cmap='viridis')\n",
    "plt.title('PCA followed by UMAP with KMeans Clustering')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ShallowLearn import Transform as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_imagery = []\n",
    "first_one = True\n",
    "only_rgb = []\n",
    "for index, i in enumerate(labels_pca):\n",
    "    # plt.imshow(ih.plot_rgb(images[index]))\n",
    "    # plt.title(i)\n",
    "    # plt.show()\n",
    "\n",
    "    if i == 2 or i == 1:\n",
    "        if first_one:\n",
    "            first_one = False\n",
    "            continue\n",
    "        fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "        ax[0].imshow(ih.plot_rgb(images[index]))\n",
    "        ax[0].set_title(f\"Original Cropped Image\")\n",
    "        lab_image = ih.plot_rgb(tf.transform_multiband_lab(images[index]))\n",
    "        ax[1].imshow(lab_image)\n",
    "        mask = np.any(lab_image != 0, axis = 2)\n",
    "        ax[1].set_title(f\"Restretched Image (LAB)\")\n",
    "        \n",
    "        restreched_hsv = tf.transform_multiband_hsv(tf.transform_multiband_lab(images[index]), max_value = 3.2)\n",
    "        restreched_hsv = ih.generate_multichannel_mask(restreched_hsv, mask)\n",
    "        restreched_hsv = ih.generate_multichannel_mask(restreched_hsv, mask)\n",
    "        # restreched_hsv = np.where(restreched_hsv<0.001, np.nan, restreched_hsv)\n",
    "        ax[2].imshow(ih.plot_rgb(restreched_hsv))\n",
    "        ax[2].set_title(f\"Restretched Image (LAB -> HSV)\")\n",
    "        \n",
    "        fixed_imagery.append(restreched_hsv)\n",
    "        plt.suptitle(f\"Restretched Image\")\n",
    "        plt.show()\n",
    "        only_rgb.append(ih.plot_rgb(restreched_hsv))\n",
    "    elif i == 0:\n",
    "        fixed_imagery.append(images[index])\n",
    "        only_rgb.append(ih.plot_rgb(images[index]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_imagery = np.array(fixed_imagery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ih.plot_histograms(fixed_imagery[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_rgb = np.array(only_rgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_rgb = only_rgb.reshape(len(only_rgb), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_rows = fixed_imagery.reshape(len(fixed_imagery), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_rows = pd.DataFrame(image_rows).dropna(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_rows.replace(0, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_rows.dropna(axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=10)\n",
    "pca_X = pca.fit_transform(only_rgb)\n",
    "\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "\n",
    "print(explained_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=10)\n",
    "pca_X = pca.fit_transform(cleaned_rows)\n",
    "\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "\n",
    "print(explained_variance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans_pca_X = KMeans(n_clusters=5)  # or however many clusters you want\n",
    "\n",
    "kmeans_pca_X.fit(pca_X)\n",
    "labels_pca = kmeans_pca_X.labels_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_model = umap.UMAP(n_neighbors=5, min_dist=0.3, metric='correlation')\n",
    "umap_model.fit_transform(pca_X)\n",
    "plt.scatter(umap_model.embedding_[:, 0], umap_model.embedding_[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "#set figure size\n",
    "kmeans_umap_pca_X = KMeans(n_clusters=4)  # or however many clusters you want\n",
    "\n",
    "kmeans_umap_pca_X.fit(pca_X)\n",
    "labels_umap_pca = kmeans_umap_pca_X.labels_\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,25))\n",
    "\n",
    "plt.scatter(umap_model.embedding_[:,0], umap_model.embedding_[:,1], c=labels_pca, cmap='rainbow')\n",
    "plt.title('PCs on whole Images after correction')\n",
    "plt.ticklabel_format(style='plain', axis='x',useOffset=False)\n",
    "\n",
    "# Plot image on top of the scatter plot in the location of the point \n",
    "for index, i in enumerate(labels_umap_pca):\n",
    "    img = ih.plot_rgb(fixed_imagery[index])\n",
    "    im = OffsetImage(img, zoom=0.2)  # Adjust zoom here\n",
    "    ab = AnnotationBbox(im, (umap_model.embedding_[index,0], umap_model.embedding_[index,1]), box_alignment=(0.5, 0.5), \n",
    "                        bboxprops = dict(edgecolor='none', alpha=0.5, boxstyle=\"square,pad=0\"))\n",
    "    plt.gca().add_artist(ab)\n",
    "\n",
    "# Print labels for each point\n",
    "label_dict = {}\n",
    "for i, txt in enumerate(labels_umap_pca):\n",
    "    # Only print one label for each cluster\n",
    "    if txt not in label_dict:\n",
    "        label_dict[txt] = 1\n",
    "        plt.annotate(txt, (umap_model.embedding_[i,0], umap_model.embedding_[i,1]), color = 'red')\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "#set figure size\n",
    "plt.figure(figsize=(15,25))\n",
    "\n",
    "plt.scatter(pca_X[:,0], pca_X[:,1], c=labels_pca, cmap='rainbow')\n",
    "plt.title('PCs on whole Images after correction')\n",
    "plt.ticklabel_format(style='plain', axis='x',useOffset=False)\n",
    "\n",
    "# Plot image on top of the scatter plot in the location of the point \n",
    "for index, i in enumerate(labels_pca):\n",
    "    img = ih.plot_rgb(fixed_imagery[index])\n",
    "    im = OffsetImage(img, zoom=0.2)  # Adjust zoom here\n",
    "    ab = AnnotationBbox(im, (pca_X[index,0], pca_X[index,1]), box_alignment=(0.5, 0.5), \n",
    "                        bboxprops = dict(edgecolor='none', alpha=0.0, boxstyle=\"square,pad=0\"))\n",
    "    plt.gca().add_artist(ab)\n",
    "\n",
    "# Print labels for each point\n",
    "label_dict = {}\n",
    "for i, txt in enumerate(labels_pca):\n",
    "    # Only print one label for each cluster\n",
    "    if txt not in label_dict:\n",
    "        label_dict[txt] = 1\n",
    "        plt.annotate(txt, (pca_X[i,0], pca_X[i,1]), color = 'red')\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, i in enumerate(labels_pca):\n",
    "    plt.imshow(ih.plot_rgb(fixed_imagery[index]))\n",
    "    plt.title(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ShallowLearn.IndiceFeatures import GenerateIndicesPerImage as gpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_w_indices = []\n",
    "for image in fixed_imagery:\n",
    "    images_w_indices.append(gpi(image).indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_imagery = np.concatenate((fixed_imagery, np.array(images_w_indices)), axis = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer, MinMaxScaler\n",
    "\n",
    "# Define the columns for each transformer\n",
    "power_transformer_columns = ['B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B09', 'B10', 'B11', 'B12','calculate_water_surface_index']\n",
    "standard_scaler_columns = ['bgr', 'ci', 'ndci', 'oci', 'ssi', 'ti', 'wqi']\n",
    "minmax_scaler_columns = ['B01', 'calculate_pseudo_subsurface_depth']\n",
    "# Create transformers\n",
    "power_transformer_transformer = ('power_transformer', PowerTransformer(), power_transformer_columns)\n",
    "standard_scaler_transformer = ('standard_scaler', StandardScaler(), standard_scaler_columns)\n",
    "minmax_scaler_transformer = ('minmax_scaler', MinMaxScaler(), minmax_scaler_columns)\n",
    "# Initialize ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        power_transformer_transformer,\n",
    "        standard_scaler_transformer,\n",
    "        minmax_scaler_transformer\n",
    "        ]\n",
    ")\n",
    "\n",
    "# Initialize Pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del features[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_imagery_copy = fixed_imagery.reshape(-1, len(features))\n",
    "df = pd.DataFrame(fixed_imagery_copy, columns = features).dropna()\n",
    "transformed_data = pipeline.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = pd.DataFrame(transformed_data, columns = pipeline.feature_names_in_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_pca_tsne = pipeline_pca_tsne.fit_transform(transformed_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('/media/ziad/Expansion/Cleaned_Data_Directory/X_5pca_2tsne.npy', X_pca_tsne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data.to_csv(\"../Data/transformed_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca_data = pca.fit_transform(transformed_data)\n",
    "\n",
    "plt.scatter(pca_data[:,0], pca_data[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.get_covariance()\n",
    "#make a covariance plot of the first two principal components\n",
    "plt.figure(figsize=(20,20))\n",
    "covariance = pd.DataFrame(pca.get_covariance(), columns = features).sort_values(by = \"B02\", ascending = False)\n",
    "sns.heatmap(covariance, annot=True, fmt='.2f', cmap='Blues',xticklabels=features, yticklabels=features)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_data = transformed_data[['B04','B03','B02','B08']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2, random_state=42)\n",
    "pca_data = pca.fit_transform(transformed_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ShallowLearn.EmbeddingVis import convert_colour_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_col = convert_colour_space(reduced_data, [\"B04\", \"B03\", \"B02\"], alpha = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def reshape_to_square_v2(image):\n",
    "    # Calculate the total number of elements divided by the channel size (4 in this case)\n",
    "    total_elements = image.size // image.shape[-1]\n",
    "    \n",
    "    # Find n\n",
    "    n = math.ceil(math.sqrt(total_elements))\n",
    "    \n",
    "    # Create a zero-filled reshaped_image\n",
    "    reshaped_image = np.zeros((n, n, 4))\n",
    "    \n",
    "    # Flatten the original image for easier indexing\n",
    "    flat_image = image.reshape(-1, image.shape[-1])\n",
    "    \n",
    "    # Fill the reshaped_image\n",
    "    for idx, row in enumerate(flat_image):\n",
    "        i = idx // n\n",
    "        j = idx % n\n",
    "        reshaped_image[i, j] = row\n",
    "        \n",
    "    return reshaped_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = MinMaxScaler(feature_range=(0,255))\n",
    "# reduced_copy = scaler.fit_transform(reduced_data.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = reshape_to_square_v2(np.expand_dims(np.array(reduced_data), axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_multidimensional_data(data):\n",
    "    \"\"\"\n",
    "    Sorts a multidimensional array based on the average value of the last dimension.\n",
    "\n",
    "    Parameters:\n",
    "    - data (ndarray): A multidimensional numpy array.\n",
    "\n",
    "    Returns:\n",
    "    - ndarray: The data sorted by the average value of the last dimension.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute the 'sorting criterion' as the mean along the last axis\n",
    "    sorting_criterion = np.mean(data, axis=-1)\n",
    "\n",
    "    # Get sorting indices from sorting criterion\n",
    "    sorting_indices = np.argsort(sorting_criterion.ravel())\n",
    "\n",
    "    # Flatten and sort the original data with these indices\n",
    "    sorted_flattened = data.reshape(-1, data.shape[-1])[sorting_indices]\n",
    "\n",
    "    # Reshape to get the sorted data\n",
    "    sorted_data = sorted_flattened.reshape(data.shape)\n",
    "    \n",
    "    return sorted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_image = sort_multidimensional_data(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(tf.transform_lab_stretch(sorted_image)[:,:,:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_image = np.uint8(tf.LCE_multi(sorted_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sorted_image[:,:,:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sorted_image[:,:,:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plot with size proportional to 'B08' value\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(pca_data[:,0], pca_data[:,1], c=color_col)  # Scale size as needed\n",
    "plt.xlabel('PC0')\n",
    "plt.ylabel('PC1')\n",
    "# plt.xlim(-3,4)\n",
    "# plt.ylim(-3,2)\n",
    "plt.title('2D PCA embeddings with RGB colors (B4,B3,B2) and size proportional to B08')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plot with size proportional to 'B08' value\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(pca_data[:,0], pca_data[:,1], c=color_col)  # Scale size as needed\n",
    "plt.xlabel('PC0')\n",
    "plt.ylabel('PC1')\n",
    "plt.xlim(-20,20)\n",
    "plt.ylim(-20,20)\n",
    "plt.title('2D PCA embeddings with RGB colors (B4,B3,B2) and size proportional to B08')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_copy = reduced_data.copy()\n",
    "# Ensure all values are within the range of -1 to 1\n",
    "for column in ['B04', 'B03', 'B02', 'B08']:\n",
    "    reduced_copy[column] = np.clip(reduced_copy[column], -1, 1)\n",
    "\n",
    "# Convert the values in the columns from the range of -1 to 1 to 0 to 1 (since RGB values and alpha are in the range 0 to 1)\n",
    "for column in ['B04', 'B03', 'B02', 'B08']:\n",
    "    reduced_copy[column] = (reduced_copy[column] + 1) / 2\n",
    "\n",
    "# Create a new column 'color' in dataframe that will contain RGBA colors for each row\n",
    "reduced_copy['color'] = list(zip(reduced_copy.B04, reduced_copy.B03, reduced_copy.B02, reduced_copy.B08 / 10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plot with size proportional to 'B08' value\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(pca_data[:,0], pca_data[:,1], c=reduced_copy['color'], s=reduced_copy['B08']*100)  # Scale size as needed\n",
    "plt.xlabel('PC0')\n",
    "plt.ylabel('PC1')\n",
    "plt.xlim(-3,4)\n",
    "plt.ylim(-3,2)\n",
    "plt.title('2D PCA embeddings with RGB colors (B4,B3,B2) and size proportional to B08')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "umap_model =  umap.UMAP(min_dist = 1, n_neighbors = 300 , random_state = 42)\n",
    "sample = transformed_data.sample(200_000)\n",
    "embedding = umap_model.fit_transform(sample)\n",
    "\n",
    "# Plot the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample_copy = sample.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample = sample_copy.copy()\n",
    "# Ensure all values are within the range of -1 to 1\n",
    "for column in ['B04', 'B03', 'B02', 'B08']:\n",
    "    sample[column] = np.clip(sample[column], -1, 1)\n",
    "\n",
    "# Convert the values in the columns from the range of -1 to 1 to 0 to 1 (since RGB values and alpha are in the range 0 to 1)\n",
    "for column in ['B04', 'B03', 'B02', 'B08']:\n",
    "    sample[column] = (sample[column] + 1) / 2\n",
    "\n",
    "# Create a new column 'color' in dataframe that will contain RGBA colors for each row\n",
    "sample['color'] = list(zip(sample.B04, sample.B03, sample.B02, sample.B08 / 10))\n",
    "\n",
    "# Create scatter plot with size proportional to 'B08' value\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(embedding[:,0], embedding[:,1], c=sample['color'], s=sample['B08']*100)  # Scale size as needed\n",
    "plt.title('2D Umap embeddings with RGB colors (B4,B3,B2) and size proportional to B08')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=5)\n",
    "pca_data = pca.fit(transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = transformed_data.sample(200_000, random_state = 42)\n",
    "\n",
    "umap_model =  umap.UMAP(min_dist = 1, n_neighbors = 300 , random_state = 42)\n",
    "embedding = umap_model.fit_transform(pca.transform(sample))\n",
    "\n",
    "# Plot the results\n",
    "\n",
    "#sample = sample_copy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_copy = sample.copy()\n",
    "\n",
    "for column in ['B04', 'B03', 'B02', 'B08']:\n",
    "    sample_copy[column] = np.clip(sample_copy[column], -1, 1)\n",
    "\n",
    "# Convert the values in the columns from the range of -1 to 1 to 0 to 1 (since RGB values and alpha are in the range 0 to 1)\n",
    "for column in ['B04', 'B03', 'B02', 'B08']:\n",
    "    sample_copy[column] = (sample_copy[column] + 1) / 2\n",
    "\n",
    "# Create a new column 'color' in dataframe that will contain RGBA colors for each row\n",
    "sample_copy['color'] = list(zip(sample_copy.B04, sample_copy.B03, sample_copy.B02, sample_copy.B08 / 10))\n",
    "\n",
    "# Create scatter plot with size proportional to 'B08' value\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(embedding[:,0], embedding[:,1], c=sample_copy['color'], s=sample_copy['B08']*100)  # Scale size as needed\n",
    "plt.title('2D Umap embeddings with RGB colors (B4,B3,B2) and size proportional to B08')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = transformed_data.sample(200_000, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "umap_model =  umap.UMAP(min_dist = 1, n_neighbors = 300 , random_state = 42, n_components = 10)\n",
    "embedding = umap_model.fit_transform(sample)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pca = PCA(n_components=10)\n",
    "pca_data = pca.fit_transform(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.explained_variance_ratio_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = convert_colour_space(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(pca_data[:,0], pca_data[:,1], c=col)  # Scale size as needed\n",
    "plt.title('2D UMAP to PCA embeddings with RGB colors (B4,B3,B2) and size proportional to B08')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_copy = sample.copy()\n",
    "\n",
    "for column in ['B04', 'B03', 'B02', 'B08']:\n",
    "    sample_copy[column] = np.clip(sample_copy[column], -1, 1)\n",
    "\n",
    "# Convert the values in the columns from the range of -1 to 1 to 0 to 1 (since RGB values and alpha are in the range 0 to 1)\n",
    "for column in ['B04', 'B03', 'B02', 'B08']:\n",
    "    sample_copy[column] = (sample_copy[column] + 1) / 2\n",
    "\n",
    "# Create a new column 'color' in dataframe that will contain RGBA colors for each row\n",
    "sample_copy['color'] = list(zip(sample_copy.B04, sample_copy.B03, sample_copy.B02, sample_copy.B08 / 10))\n",
    "\n",
    "# Create scatter plot with size proportional to 'B08' value\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(pca_data[:,0], pca_data[:,1], c=sample_copy['color'], s=sample_copy['B08']*100)  # Scale size as needed\n",
    "plt.title('2D UMAP to PCA embeddings with RGB colors (B4,B3,B2) and size proportional to B08')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = transformed_data.sample(500_000, random_state = 42)\n",
    "\n",
    "pca = PCA(n_components=10)\n",
    "pca_data = pca.fit_transform(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import manifold\n",
    "# tsne = manifold.TSNE(n_components = 2,learning_rate=400, perplexity = 25, random_state = 42, verbose = 2, n_iter = 2000, n_jobs=-1)\n",
    "# transformed_data = tsne.fit_transform(pca_data)\n",
    "tsne = manifold.TSNE(n_components = 2,learning_rate=500, perplexity = 25, random_state = 42, verbose = 2, n_iter = 2000, n_jobs=-1)\n",
    "tsne_data = tsne.fit_transform(pca_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_copy = sample.copy()\n",
    "\n",
    "for column in ['B04', 'B03', 'B02', 'B08']:\n",
    "    sample_copy[column] = np.clip(sample_copy[column], -1, 1)\n",
    "\n",
    "# Convert the values in the columns from the range of -1 to 1 to 0 to 1 (since RGB values and alpha are in the range 0 to 1)\n",
    "for column in ['B04', 'B03', 'B02', 'B08']:\n",
    "    sample_copy[column] = (sample_copy[column] + 1) / 2\n",
    "\n",
    "# Create a new column 'color' in dataframe that will contain RGBA colors for each row\n",
    "sample_copy['color'] = list(zip(sample_copy.B04, sample_copy.B03, sample_copy.B02, sample_copy.B08 / 10))\n",
    "\n",
    "# Create scatter plot with size proportional to 'B08' value\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(tsne_data[:,0], tsne_data[:,1], c=sample_copy['color'], s=sample_copy['B08']*10)  # Scale size as needed\n",
    "plt.title('2D PCA embeddings to t-sne with RGB colors (B4,B3,B2) and size proportional to B08')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_copy = sample.copy()\n",
    "\n",
    "for column in ['B04', 'B03', 'B02', 'B08']:\n",
    "    sample_copy[column] = np.clip(sample_copy[column], -1, 1)\n",
    "\n",
    "# Convert the values in the columns from the range of -1 to 1 to 0 to 1 (since RGB values and alpha are in the range 0 to 1)\n",
    "for column in ['B04', 'B03', 'B02', 'B08']:\n",
    "    sample_copy[column] = (sample_copy[column] + 1) / 2\n",
    "\n",
    "# Create a new column 'color' in dataframe that will contain RGBA colors for each row\n",
    "sample_copy['color'] = list(zip(sample_copy.B04, sample_copy.B03, sample_copy.B02))\n",
    "\n",
    "# Create scatter plot with size proportional to 'B08' value\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(tsne_data[:,0], tsne_data[:,1], c=sample_copy['color'])  # Scale size as needed\n",
    "plt.title('2D UMAP to PCA embeddings with RGB colors (B4,B3,B2) and size proportional to B08')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_copy = sample.copy()\n",
    "\n",
    "for column in ['B04', 'B03', 'B02', 'B08']:\n",
    "    sample_copy[column] = np.clip(sample_copy[column], -1, 1)\n",
    "\n",
    "# Convert the values in the columns from the range of -1 to 1 to 0 to 1 (since RGB values and alpha are in the range 0 to 1)\n",
    "for column in ['B04', 'B03', 'B02', 'B08']:\n",
    "    sample_copy[column] = (sample_copy[column] + 1) / 2\n",
    "\n",
    "# Create a new column 'color' in dataframe that will contain RGBA colors for each row\n",
    "sample_copy['color'] = list(zip(sample_copy.B04, sample_copy.B03, sample_copy.B02, sample_copy.B08 / 10))\n",
    "\n",
    "# Create scatter plot with size proportional to 'B08' value\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(tsne_data[:,0], tsne_data[:,1], c=sample_copy['color'], s=sample_copy['B08']*100)  # Scale size as needed\n",
    "plt.title('2D UMAP to PCA embeddings with RGB colors (B4,B3,B2) and size proportional to B08')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fit a KMeans model to the PCA -> t-SNE data\n",
    "kmeans_pca = KMeans(n_clusters=10)  # or however many clusters you want\n",
    "kmeans_pca.fit(tsne_data)\n",
    "labels_pca_tsne = kmeans_pca.labels_\n",
    "\n",
    "# Create a 2D scatter plot for PCA -> t-SNE with points colored by their cluster membership\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# Find unique labels and their corresponding colors\n",
    "unique_labels = list(set(labels_pca_tsne))\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(unique_labels)))\n",
    "\n",
    "for i, label in enumerate(unique_labels):\n",
    "    plt.scatter(tsne_data[labels_pca_tsne == label, 0], \n",
    "                tsne_data[labels_pca_tsne == label, 1], \n",
    "                color=colors[i], \n",
    "                label=f'Cluster {label}', \n",
    "                s=10)\n",
    "\n",
    "plt.legend()\n",
    "plt.title('PCA to t-sne followed by KMeans Clustering')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_pca_umap = pipeline_pca_umap.fit_transform(reduced_data.sample(300_000, random_state=42))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fit a KMeans model to the PCA -> t-SNE data\n",
    "kmeans_pca_tsne = KMeans(n_clusters=10)  # or however many clusters you want\n",
    "kmeans_pca_tsne.fit(X_pca_umap)\n",
    "labels_pca_tsne = kmeans_pca_tsne.labels_\n",
    "\n",
    "# Create a 2D scatter plot for PCA -> t-SNE with points colored by their cluster membership\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.scatter(X_pca_umap[:, 0], X_pca_umap[:, 1], c=labels_pca_tsne, s=10, cmap='viridis')\n",
    "plt.title('PCA followed by umap with KMeans Clustering')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fit a KMeans model to the PCA -> t-SNE data\n",
    "kmeans_pca_tsne = KMeans(n_clusters=8)  # or however many clusters you want\n",
    "kmeans_pca_tsne.fit(X_pca_umap)\n",
    "labels_pca_tsne = kmeans_pca_tsne.labels_\n",
    "\n",
    "# Create a 2D scatter plot for PCA -> t-SNE with points colored by their cluster membership\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.scatter(X_pca_umap[:, 0], X_pca_umap[:, 1], c=labels_pca_tsne, s=10, cmap='viridis')\n",
    "plt.title('PCA followed by t-SNE with KMeans Clustering')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca = pipeline_pca.fit_transform(transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Fit a KMeans model to the PCA -> t-SNE data\n",
    "kmeans_pca_tsne = KMeans(n_clusters=3)  # or however many clusters you want\n",
    "kmeans_pca_tsne.fit(X_pca_tsne)\n",
    "labels_pca_tsne = kmeans_pca_tsne.labels_\n",
    "\n",
    "# Create a 2D scatter plot for PCA -> t-SNE with points colored by their cluster membership\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.scatter(X_pca_tsne[:, 0], X_pca_tsne[:, 1], c=labels_pca_tsne, s=10, cmap='viridis')\n",
    "plt.title('PCA followed by t-SNE with KMeans Clustering')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "#import test train split\n",
    "from sklearn.model_selection import train_test_split\n",
    "#import metrics accuracy \n",
    "from sklearn.metrics import accuracy_score\n",
    "# Assuming your preprocessed data is X and the kmeans labels are y\n",
    "X = sample.copy()\n",
    "y = labels_pca_tsne\n",
    "#test train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Create a new pipeline with XGBoost\n",
    "# pipeline_xgb = Pipeline(steps=[('preprocessor', pipeline),\n",
    "#                                ('classifier', XGBClassifier())])\n",
    "clf = XGBClassifier()\n",
    "# Fit the entire pipeline\n",
    "clf.fit(X_train, y_train)\n",
    "# Predict the labels of the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "# Compute the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import recall and precision\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "# test recall and precision\n",
    "print('Recall:', recall_score(y_test, y_pred, average='weighted'))\n",
    "print('Precision:', precision_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_combined[0].reshape(-1, 23).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_method(image):\n",
    "    temp = image.copy()\n",
    "    original_shape = image.shape\n",
    "    temp = temp.reshape(-1, 23)\n",
    "    temp = pd.DataFrame(temp, columns=pipeline.feature_names_in_)\n",
    "    temp = pipeline.transform(temp)\n",
    "    temp = pd.DataFrame(temp, columns=pipeline.feature_names_in_)\n",
    "    #temp = temp[reduced_data.columns]\n",
    "    pred = clf.predict(temp)\n",
    "    pred = pred.reshape(original_shape[:-1] + (1,))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(image):\n",
    "    temp = image.copy()\n",
    "    original_shape = temp.shape\n",
    "    temp = temp.reshape(-1, temp.shape[-1])\n",
    "    temp = pd.DataFrame(temp, columns=pipeline.feature_names_in_)\n",
    "    temp = pipeline.transform(temp)\n",
    "    temp = pd.DataFrame(temp, columns=pipeline.feature_names_in_)\n",
    "    #temp = temp[reduced_data.columns]\n",
    "    return temp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bar plot of feature importance of the classifier \n",
    "pd.DataFrame(clf.feature_importances_, columns = ['Importance'], index = pipeline.feature_names_in_).sort_values(by = 'Importance', ascending = False).plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(labels_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_imagery[img_no].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_no = 14\n",
    "ih.plot_rgb(data_combined[img_no], plot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ih.discrete_implot(predict_method(data_combined[img_no]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2D scatter plot for PCA -> UMAP\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.scatter(X_pca_umap[:, 0], X_pca_umap[:, 1], s=10)\n",
    "plt.title('PCA followed by UMAP')\n",
    "plt.show()\n",
    "\n",
    "# Create a 2D scatter plot for PCA\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], s=10)\n",
    "plt.title('PCA')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "explainer = shap.TreeExplainer(clf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_image_single = transform_data(data_combined[img_no])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate SHAP values\n",
    "\n",
    "shap_values = explainer.shap_values(transformed_image_single)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot summary of SHAP values using matplotlib\n",
    "shap.summary_plot(shap_values, transformed_image_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_shape = data_combined[img_no].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_shap = select_channels(shap_values[0].reshape(original_shape[0], original_shape[1], 23), [14,12,19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_vals = shap_values[0].reshape(original_shape[0], original_shape[1], 23)\n",
    "for i in range(23):\n",
    "    plt.title(features[i]   + \" SHAP Values\")\n",
    "    plt.imshow(shap_vals[:, :, i])\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(shap_values[1].reshape(original_shape[0], original_shape[1], 4)[:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "for i in range(10):\n",
    "    plt.imshow(scaler.fit_transform(shap_values[i]).reshape(original_shape[0], original_shape[1], 4)[:,:,:3])\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(scaler.fit_transform(shap_values[i]).reshape(original_shape[0], original_shape[1], 4)[:,:,3])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate SHAP values\n",
    "transformed_image_single = sorted_image.reshape(-1, 4)\n",
    "shap_values = explainer.shap_values(transformed_image_single)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "original_shape = sorted_image.shape\n",
    "for i in range(10):\n",
    "    plt.imshow(scaler.fit_transform(shap_values[i]).reshape(original_shape[0], original_shape[1], 4)[:,:,:4])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "original_shape = sorted_image.shape\n",
    "for i in range(10):\n",
    "    plt.imshow(scaler.fit_transform(shap_values[i]).reshape(original_shape[0], original_shape[1], 4)[:,:,:4])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ShallowLearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
